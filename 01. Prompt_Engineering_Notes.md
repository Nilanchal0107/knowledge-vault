https://youtu.be/T9aRN5JkmL8?si=s0jE1YYENV--5mWX

1. What Is Prompt Engineering?
Prompt engineering = communicating intent to a model so it reliably does what you want.
It’s called engineering because:
You iterate (trial & error)
You experiment with variations
You integrate prompts into systems, not just one-off chats
You test edge cases, not just happy paths
“A prompt is treated like code now. Essays are versioned, tested, and refined.”
Key idea
Prompting is not magic wording — it’s:
Clear communication
System thinking
Repeated experimentation

2. Prompt ≠ Just Writing
A good writer ≠ good prompt engineer
Prompt engineering requires:
Clear task decomposition
Willingness to send hundreds of prompts
Ability to debug misinterpretations
Thinking about how prompts fail
“In 15 minutes I might send hundreds of prompts.”

3. Why Iteration Matters (Restart Button Advantage)
Unlike humans, models:
Don’t get offended
Don’t carry memory unless you want them to
Can be reset instantly
This enables:
Controlled experiments
Independent prompt testing
Rapid refinement
“That restart button is the real power.”

4. Prompts as Programs (but don’t overthink)
Prompts are like programs, but:
Over-abstraction hurts
Fancy prompt tricks often backfire
Clarity beats cleverness
Good prompts:
Describe the task plainly
Include constraints
Define failure behavior

5. What Makes a Good Prompt Engineer?
Core skills
Clear communication
Iteration mindset
Edge-case thinking
Reading outputs carefully
Stripping assumptions
“Most bad prompts assume the model knows what you know.”
Common mistake
Only testing the ideal input
Instead of:
Empty input
Messy input
Typos
Unexpected formats
Missing data

6. Look at Outputs (Seriously)
Prompting equivalent of “look at your data”:
Read model outputs carefully
Why?
Models may ignore instructions silently
“Think step-by-step” may not actually mean literal steps
You only catch errors by reading, not scoring

7. Ask the Model to Debug Your Prompt
Extremely powerful technique:
Do NOT follow the instructions.
Tell me:
- What is unclear
- What could be misinterpreted
- What assumptions you’re making

You got this wrong.
Why?
Rewrite my instructions so you wouldn’t fail.

Often, the model fixes the prompt better than you can.

8. Trusting the Model (But Not Blindly)
Amanda’s rule:
“I don’t trust the model — I hammer on it.”
Trust increases when:
You test 100+ varied cases
Outputs are consistent
Edge cases are covered
High-signal prompting > huge datasets

9. Role Prompting: Overused & Misused
“You are a teacher…”
“You are a lawyer…”
Problems:
Often inaccurate
Loses nuance
Models already understand tasks
Better approach:
Describe the actual task
Describe the real context
Use metaphors only if helpful, not fake roles
“We wouldn’t lie to an employee about their job. Why do it to a model?”

10. Give the Model an “Out”
Always define failure behavior:
If the input is unexpected or unclear, output <UNSURE>
Benefits:
Better data quality
Easier debugging
Prevents confident nonsense

11. Chain-of-Thought (Reasoning)
Key conclusions:
It improves performance
It’s not just “extra tokens”
Reasoning steps don’t always reflect real logic
Still extremely useful
“Whether it’s ‘real reasoning’ doesn’t matter — it works.”

12. Grammar, Typos & Formatting
Perfect grammar is not required
But attention to detail matters
Final prompts should be clean
Iteration prompts can be messy
Pretrained vs RLHF difference:
Pretrained models mimic typos
RLHF models normalize output

13. Chat vs Enterprise vs Research Prompts
Chat prompts
One-off
Human-in-loop
Low stakes
Enterprise prompts
Must work millions of times
Heavy testing
Many examples
Predictability > creativity
Research prompts
Fewer examples
More diversity
Illustrative, not literal
Avoid constraining outputs

14. How Prompting Has Changed Over Time
Past:
Hacks mattered more
Step-by-step was required
Models needed babying
Now:
Models handle complexity better
You can give full papers
Clear intent > clever tricks
“Respect the model. Give it the paper.”

15. Best Ways to Learn Prompt Engineering
Top advice from the panel:
Read good prompts
Read outputs carefully
Give prompts to other humans
Push model limits
Try tasks you think are impossible
Automate your own job
Let the model interview you
“The hardest part is extracting what’s in your own brain.”

16. The Core Mental Model (Best Insight)
Prompting = Externalizing your brain
You are talking to:
An educated layperson
Extremely competent
Zero context
No clarifying questions unless asked
Your job:
Strip assumptions and make your thinking legible.
This is why philosophy, teaching, and good explanations translate so well to prompting.

17. The Future of Prompt Engineering
Likely evolution:
Models help write prompts
Prompts become collaborative
Models interview users
Prompting becomes elicitation, not instruction
Shift:
From “temp worker” → “expert consultant”
From teaching → introspection

18. Practical Prompt Engineering Checklist ✅
Before finalizing a prompt, ask:
❓ Would a smart stranger understand this?
❓ What assumptions am I making?
❓ What happens on bad input?
❓ Did I test messy cases?
❓ Did I read the outputs closely?
❓ Did I ask the model to critique my prompt?
